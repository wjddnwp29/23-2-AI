{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-MbzILFlPHBbyPso--03nzB32dnRt-5C",
      "authorship_tag": "ABX9TyNsJNKAn+rz8lB1vc6vHfVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooje-jung/23-2-AI/blob/main/SIMCSE%EC%84%B1%EB%8A%A5%EB%B9%84%EA%B5%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 구글 드라이브 코랩에 마운트하기\n"
      ],
      "metadata": {
        "id": "zQiu2QtwXpiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRLj6fW0UxKN",
        "outputId": "ea095867-8126-4805-8df4-fe04d179df13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 훈련데이터 가져오기\n"
      ],
      "metadata": {
        "id": "xxfCAiSNYaNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/korsts.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "df = df.dropna()\n",
        "df\n",
        "df = df.drop(columns=[\"Unnamed: 3\"])\n"
      ],
      "metadata": {
        "id": "O-G2P4Cfp1d9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "a3L43TDOvD93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1c7cdec2-1a4a-4d07-9537-d0973348cab1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                          sentence1  \\\n",
              "0    4.2                       이란은 또한 NPT와 IAEA의 서명을 받았습니다.   \n",
              "1    4.4        브랜데이스의 관계자들은 이것이 \"매우 가슴 아픈\" 캠퍼스의 시간이라고 말했다.   \n",
              "2    3.2  그러나 아리 플라이셔 백악관 대변인은 어제 \"이란 사람들이 알 카 아다를 체포하는 ...   \n",
              "3    2.8               하지만 나는 낮은 기준보다는 높은 기준에 대해 이야기하고 싶다.\"   \n",
              "4    4.6              마리아 쳉 대변인은 \"이는 고립된 사건과 매우 흡사하다\"고 말했다.   \n",
              "5    3.2          아마도, 노년은 우리가 우리의 강점과 약점을 이해할 수 있도록 도와줍니다.   \n",
              "6    4.8   나는 내가 최고의 테니스를 치는 경우에만 이것을 할 수 있다고 믿고 법원에 갈 것이다.   \n",
              "\n",
              "                                           sentence2  \n",
              "0  이란은 또한 NPT와 IAEA의 서명인 EC 팩토이드를 사랑해야 합니다.\\n\\nma...  \n",
              "1  이번은 브랜데이스 대학 전체 지역사회에 매우 가슴 아픈 시기다.\\n\\nmain-ne...  \n",
              "2  이란 인들이 알 카에다를 체포하는 측면에서 취했다고 주장하는 조치는 불충분합니다.\\...  \n",
              "3  나는 오히려 부정적인 것보다 긍정적인 숫자에 대해 이야기하고 싶다.\\n\\nmain-...  \n",
              "4  세계 보건기구 대변인 마리아 쳉은 고립된 사건과 매우 흡사합니다.\\n\\nmain-n...  \n",
              "5  아마도, 노년기는 우리의 힘과 약점과 세계의 현실을 이해하는 데 도움이 됩니다.\\n...  \n",
              "6  나는 내가 이것을할 수 있다고 확신하고 있었지만, 경우에만 나는 최고의 테니스를 칠...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-464844c0-deb1-4afd-8ed2-0d983c9a09c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.2</td>\n",
              "      <td>이란은 또한 NPT와 IAEA의 서명을 받았습니다.</td>\n",
              "      <td>이란은 또한 NPT와 IAEA의 서명인 EC 팩토이드를 사랑해야 합니다.\\n\\nma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.4</td>\n",
              "      <td>브랜데이스의 관계자들은 이것이 \"매우 가슴 아픈\" 캠퍼스의 시간이라고 말했다.</td>\n",
              "      <td>이번은 브랜데이스 대학 전체 지역사회에 매우 가슴 아픈 시기다.\\n\\nmain-ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>그러나 아리 플라이셔 백악관 대변인은 어제 \"이란 사람들이 알 카 아다를 체포하는 ...</td>\n",
              "      <td>이란 인들이 알 카에다를 체포하는 측면에서 취했다고 주장하는 조치는 불충분합니다.\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.8</td>\n",
              "      <td>하지만 나는 낮은 기준보다는 높은 기준에 대해 이야기하고 싶다.\"</td>\n",
              "      <td>나는 오히려 부정적인 것보다 긍정적인 숫자에 대해 이야기하고 싶다.\\n\\nmain-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>마리아 쳉 대변인은 \"이는 고립된 사건과 매우 흡사하다\"고 말했다.</td>\n",
              "      <td>세계 보건기구 대변인 마리아 쳉은 고립된 사건과 매우 흡사합니다.\\n\\nmain-n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.2</td>\n",
              "      <td>아마도, 노년은 우리가 우리의 강점과 약점을 이해할 수 있도록 도와줍니다.</td>\n",
              "      <td>아마도, 노년기는 우리의 힘과 약점과 세계의 현실을 이해하는 데 도움이 됩니다.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.8</td>\n",
              "      <td>나는 내가 최고의 테니스를 치는 경우에만 이것을 할 수 있다고 믿고 법원에 갈 것이다.</td>\n",
              "      <td>나는 내가 이것을할 수 있다고 확신하고 있었지만, 경우에만 나는 최고의 테니스를 칠...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-464844c0-deb1-4afd-8ed2-0d983c9a09c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-464844c0-deb1-4afd-8ed2-0d983c9a09c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-464844c0-deb1-4afd-8ed2-0d983c9a09c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c712b5ab-87e8-4ed0-b3de-34c5e043ce49\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c712b5ab-87e8-4ed0-b3de-34c5e043ce49')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c712b5ab-87e8-4ed0-b3de-34c5e043ce49 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_63bae6a5-653a-4264-a5f5-c92d2e05589b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_63bae6a5-653a-4264-a5f5-c92d2e05589b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. BERT-BASE 모델 학습\n"
      ],
      "metadata": {
        "id": "-QdRF7jqDhrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yzvjsd2CXZLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1290f52e-7489-4ff3-90e3-b108ee9c45ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "<ipython-input-4-64affb710d9e>:46: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = torch.nn.functional.mse_loss(sentence_embeddings, labels.view(-1, 1))\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# BERT 모델 및 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# 데이터 전처리\n",
        "def preprocess_data(df):\n",
        "    inputs = tokenizer(df[\"sentence1\"].tolist(), df[\"sentence2\"].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.float32)\n",
        "    return inputs, labels\n",
        "\n",
        "# 데이터 나누기\n",
        "train_data, eval_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# 학습 설정\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 3\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 미니배치 생성 및 학습\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        batch = train_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "        # 모델 학습 단계\n",
        "\n",
        "        # Forward pass(순전파)\n",
        "        outputs = model(**inputs)\n",
        "        sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Loss(손실률 계산)\n",
        "        loss = torch.nn.functional.mse_loss(sentence_embeddings, labels.view(-1, 1))\n",
        "\n",
        "        # 모델 조정 단계(손실을 최소화하는 과정)\n",
        "        # Backward pass 및 가중치 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Autograd 비활성화\n",
        "    for i in range(0, len(eval_data), batch_size):\n",
        "        batch = eval_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        sentence_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # 모든 예측값과 레이블을 리스트에 추가\n",
        "        all_preds.extend(sentence_embeddings.cpu().detach().numpy())\n",
        "        all_labels.extend(labels.cpu().detach().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값과 실제값을 텐서로 변환\n",
        "predictions = torch.tensor(all_preds)\n",
        "labels = torch.tensor(all_labels).view(-1, 1)\n",
        "\n",
        "# Mean Squared Error(평균제곱오차) 계산\n",
        "Bmse = torch.nn.functional.mse_loss(predictions, labels)\n",
        "print(f\"Mean Squared Error: {Bmse.item()}\")"
      ],
      "metadata": {
        "id": "z3EJw2sDB8--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f8bc8a-ca0d-4187-d20f-fa81b71956e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 18.639095306396484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3fb36d45eba0>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  predictions = torch.tensor(all_preds)\n",
            "<ipython-input-5-3fb36d45eba0>:6: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Bmse = torch.nn.functional.mse_loss(predictions, labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. simcse를 적용시킨 BERT-BASE 모델 학습(sup)\n"
      ],
      "metadata": {
        "id": "KlyhqZeHDpPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, AdamW, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# SimCSE 모델 정의\n",
        "class SimCSEModel(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(SimCSEModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.linear = torch.nn.Linear(768, 768)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        projected_output = self.linear(pooled_output)\n",
        "        return projected_output\n",
        "\n",
        "\n",
        "# BERT 모델 및 토크나이저 로드\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# SimCSE 모델 초기화\n",
        "simcse_model = SimCSEModel(bert_model)\n",
        "\n",
        "# 데이터 전처리\n",
        "def preprocess_data(df):\n",
        "    inputs = tokenizer(df[\"sentence1\"].tolist(), df[\"sentence2\"].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.float32)\n",
        "    return inputs, labels\n",
        "\n",
        "# 데이터 나누기\n",
        "train_data, eval_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(simcse_model.parameters(), lr=5e-5)\n",
        "\n",
        "# 학습 설정\n",
        "device = torch.device(\"cpu\")\n",
        "simcse_model.to(device)\n",
        "simcse_model.train()\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 3\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        batch = train_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass(순전파)\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # Loss\n",
        "        loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n",
        "\n",
        "        # Backward pass 및 가중치 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(eval_data), batch_size):\n",
        "        batch = eval_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass(순전파)\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # 모든 예측값과 레이블을 리스트에 추가\n",
        "        all_preds.extend(outputs.cpu().detach().numpy())\n",
        "        all_labels.extend(labels.cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "OWMeYmlaDtzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1a64ff-0496-40b6-e22c-6155208f094a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "<ipython-input-6-a560c0789c64>:60: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값과 실제값을 텐서로 변환\n",
        "predictions = torch.tensor(all_preds)\n",
        "labels = torch.tensor(all_labels).view(-1, 1)\n",
        "\n",
        "# Mean Squared Error 계산\n",
        "sbmse = torch.nn.functional.mse_loss(predictions, labels)\n",
        "print(f\"Mean Squared Error: {sbmse.item()}\")"
      ],
      "metadata": {
        "id": "piqrlN2VFYUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b546341-978f-49f5-ebde-a4f5641be317"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 17.005983352661133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fb3566741215>:6: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  sbmse = torch.nn.functional.mse_loss(predictions, labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. KOBERT 모델 학습\n"
      ],
      "metadata": {
        "id": "CXcPCeWPJpcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kobert-transformers"
      ],
      "metadata": {
        "id": "ke8CowDEmPfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca0fdf3-985b-4a31-90e4-032aeec7047e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kobert-transformers in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (4.35.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->kobert-transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->kobert-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AdamW, BertModel, BertTokenizer\n",
        "from kobert_transformers import get_kobert_model, get_distilkobert_model\n",
        "\n",
        "# KoBERT 모델과 토크나이저 불러오기\n",
        "kobert_model = get_kobert_model()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "\n",
        "# 데이터 전처리\n",
        "def preprocess_data(df):\n",
        "    inputs = tokenizer.batch_encode_plus(\n",
        "        df[\"sentence1\"].tolist(),\n",
        "        df[\"sentence2\"].tolist(),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.float32)\n",
        "    return inputs, labels\n",
        "\n",
        "# 데이터 나누기\n",
        "train_data, eval_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(simcse_model.parameters(), lr=5e-5)\n",
        "\n",
        "# 학습 설정\n",
        "device = torch.device(\"cpu\")\n",
        "simcse_model.to(device)\n",
        "simcse_model.train()\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 3\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        batch = train_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # Loss\n",
        "        loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n",
        "\n",
        "        # Backward pass 및 가중치 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(eval_data), batch_size):\n",
        "        batch = eval_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # 모든 예측값과 레이블을 리스트에 추가\n",
        "        all_preds.extend(outputs.cpu().detach().numpy())\n",
        "        all_labels.extend(labels.cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "7ymeOqB_mkVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd674b2-29c4-423e-d2e2-b49e6a20a4a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-ae54cd020e9e>:48: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값과 실제값을 텐서로 변환\n",
        "predictions = torch.tensor(all_preds)\n",
        "labels = torch.tensor(all_labels).view(-1, 1)\n",
        "\n",
        "# Mean Squared Error 계산\n",
        "kmse = torch.nn.functional.mse_loss(predictions, labels)\n",
        "print(f\"Mean Squared Error: {kmse.item()}\")"
      ],
      "metadata": {
        "id": "94AZNBxFoQbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc61fec-0bea-4a72-8d02-60aa5de1a62e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 16.622398376464844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-1375650eb05f>:6: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  kmse = torch.nn.functional.mse_loss(predictions, labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. SIMCSE를 적용한 KOBERT 모델 학습\n"
      ],
      "metadata": {
        "id": "PtE0kN8BopQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AdamW, BertModel, BertTokenizer\n",
        "from kobert_transformers import get_kobert_model, get_distilkobert_model\n",
        "\n",
        "# KoBERT 모델과 토크나이저 불러오기\n",
        "kobert_model = get_kobert_model()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "\n",
        "# SimCSE 모델 정의\n",
        "class SimCSEModel(torch.nn.Module):\n",
        "    def __init__(self, bert_model):\n",
        "        super(SimCSEModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.linear = torch.nn.Linear(768, 768)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        projected_output = self.linear(pooled_output)\n",
        "        return projected_output\n",
        "\n",
        "\n",
        "\n",
        "# SimCSE 모델 초기화\n",
        "simcse_model = SimCSEModel(kobert_model)\n",
        "\n",
        "# 데이터 전처리\n",
        "def preprocess_data(df):\n",
        "    inputs = tokenizer.batch_encode_plus(\n",
        "        df[\"sentence1\"].tolist(),\n",
        "        df[\"sentence2\"].tolist(),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    labels = torch.tensor(df[\"label\"].tolist(), dtype=torch.float32)\n",
        "    return inputs, labels\n",
        "\n",
        "# 데이터 나누기\n",
        "train_data, eval_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(simcse_model.parameters(), lr=5e-5)\n",
        "\n",
        "# 학습 설정\n",
        "device = torch.device(\"cpu\")\n",
        "simcse_model.to(device)\n",
        "simcse_model.train()\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 3\n",
        "batch_size = 8\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "        batch = train_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # Loss\n",
        "        loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n",
        "\n",
        "\n",
        "        # Backward pass 및 가중치 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(eval_data), batch_size):\n",
        "        batch = eval_data.iloc[i:i+batch_size]\n",
        "        inputs, labels = preprocess_data(batch)\n",
        "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = simcse_model(**inputs)\n",
        "\n",
        "        # Add all predictions and labels to lists\n",
        "        all_preds.extend(outputs.cpu().detach().numpy())\n",
        "        all_labels.extend(labels.cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "uSUduIvCot8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a99d8dcf-f1d4-4009-c03a-968ebad3a718"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4c71a5e4d552>:66: UserWarning: Using a target size (torch.Size([5, 1])) that is different to the input size (torch.Size([5, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss = torch.nn.functional.mse_loss(outputs, labels.view(-1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값과 실제값을 텐서로 변환\n",
        "predictions = torch.tensor(all_preds)\n",
        "labels = torch.tensor(all_labels).view(-1, 1)\n",
        "\n",
        "# Mean Squared Error 계산\n",
        "ksmse = torch.nn.functional.mse_loss(predictions, labels)\n",
        "print(f\"Mean Squared Error: {ksmse.item()}\")"
      ],
      "metadata": {
        "id": "r9oZyCeNo880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b09d83-05b6-43f9-d5b3-b27e6b7fd343"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 17.629135131835938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-e34cd5f685c2>:6: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  ksmse = torch.nn.functional.mse_loss(predictions, labels)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 성능비교\n",
        "KOBERT > simcse 적용한 BERT > simcse 적용한 KOBERT > BERT"
      ],
      "metadata": {
        "id": "QWBMi1oS6mQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "variables = ['Bmse', 'sbmse', 'Kmse', 'Ksmse']\n",
        "values = [Bmse.item(), sbmse.item(), kmse.item(), ksmse.item()]\n",
        "\n",
        "data = {'변수': variables, '값': values}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "ANbqoc_m7ejf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fb5676-ea9d-46ef-d969-286f2abed8de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      변수          값\n",
            "0   Bmse  18.639095\n",
            "1  sbmse  17.005983\n",
            "2   Kmse  16.622398\n",
            "3  Ksmse  17.629135\n"
          ]
        }
      ]
    }
  ]
}