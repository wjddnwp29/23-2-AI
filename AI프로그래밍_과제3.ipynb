{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjO8ioN7pogSzsnAWKNYad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wooje-jung/class-project/blob/main/AI%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D_%EA%B3%BC%EC%A0%9C3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCtjb-jl_t79",
        "outputId": "055b0eb3-5b51-4905-b5b4-e201c815ab8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.34.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (17.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브 Colab 환경에 마운트하기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfnyYShf0oAr",
        "outputId": "48bcc1b1-f092-4ece-e3bb-48300305db23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# 엑셀파일 불러오기\n",
        "dataset_train1 = pd.read_excel('/content/drive/MyDrive/katalk_data/카카오톡 대화내용.xlsx')\n",
        "\n",
        "# 정규식을 이용하여 이름, 시간, 채팅 내용 추출하기\n",
        "pattern = r'(\\S+)\\s\\[([^\\]]+)\\]\\s(.+)'\n",
        "dataset_train1[['이름', '시간', '채팅']] = dataset_train1['채팅'].str.extract(pattern)\n",
        "\n",
        "# 시간 정보 삭제하기\n",
        "new_data = dataset_train1.drop(columns=['시간'])\n",
        "\n",
        "# 결과 데이터프레임 출력하기\n",
        "print(new_data[['이름', '채팅']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QJP16w_0qQC",
        "outputId": "8a2d217b-581e-4d53-dce6-e4814d651ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       이름                        채팅\n",
            "0     정성현                우제야 생일축하해!\n",
            "1     정성현                우제야 생일축하해!\n",
            "2     정현철                정보)우제 생일아님\n",
            "3     정성현                  오늘 29일인줄\n",
            "4     구도현               난 내년에 축하할게~\n",
            "...   ...                       ...\n",
            "6333  정성현                   먼가 크리미한\n",
            "6334  정현철                      ㄷㄷㄷㄷ\n",
            "6335  정우제                        님들\n",
            "6336  정우제  이거 채팅방내용 추출하는걸로 과제발표해도됨?\n",
            "6337  정현철                  추출임 유출임?\n",
            "\n",
            "[6338 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# 훈련된 모델과 토크나이저를 불러오기\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# 임베딩을 저장할 리스트\n",
        "chat_embeddings = []\n",
        "\n",
        "# 채팅 메시지를 반복하고 임베딩을 저장하기\n",
        "for chat_text in new_data['채팅']:\n",
        "    inputs = tokenizer(chat_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    chat_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    chat_embeddings.append(chat_embedding)\n",
        "\n",
        "# chat_embeddings 리스트를 데이터프레임으로 변환하기\n",
        "embedding_df = pd.DataFrame(chat_embeddings)\n",
        "\n",
        "# 만들어진 임베딩을 원래 데이터프레임에 새 열로 추가하기\n",
        "new_data = pd.concat([new_data, embedding_df], axis=1)\n",
        "\n",
        "\n",
        "print(new_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz3Psz3NBrYd",
        "outputId": "6f3db0c8-e663-4377-81be-8c7c07a98e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            채팅  이름         0         1         2         3  \\\n",
            "0                   우제야 생일축하해!   2 -0.509945 -0.293520  0.324045 -0.433693   \n",
            "1                   우제야 생일축하해!   2 -0.509945 -0.293520  0.324045 -0.433693   \n",
            "2                   정보)우제 생일아님   4 -0.431421 -0.409895  0.401063 -0.601982   \n",
            "3                     오늘 29일인줄   2 -0.400465 -0.485173  0.289293 -0.685321   \n",
            "4                  난 내년에 축하할게~   0 -0.365748 -0.245194  0.375380 -0.424923   \n",
            "...                        ...  ..       ...       ...       ...       ...   \n",
            "6333                   먼가 크리미한   2 -0.142867 -0.400498 -0.037008 -0.515675   \n",
            "6334                      ㄷㄷㄷㄷ   4 -0.402784  0.145996 -0.379183 -0.277948   \n",
            "6335                        님들   3 -0.204651 -0.638040  0.056954 -0.162104   \n",
            "6336  이거 채팅방내용 추출하는걸로 과제발표해도됨?   3 -0.306189 -0.209753  0.316369 -0.478991   \n",
            "6337                  추출임 유출임?   4 -0.411519 -0.578170  0.509110 -0.478210   \n",
            "\n",
            "             4         5         6         7  ...       758       759  \\\n",
            "0     0.179297 -0.208565 -0.035053  0.570758  ... -0.754800 -0.570895   \n",
            "1     0.179297 -0.208565 -0.035053  0.570758  ... -0.754800 -0.570895   \n",
            "2     0.126904 -0.122199  0.110885  0.516812  ... -0.595081 -0.524095   \n",
            "3     0.167956 -0.102682 -0.181855  0.549427  ... -0.608365 -0.356525   \n",
            "4     0.070305 -0.250488  0.100422  0.348640  ... -0.695479 -0.403104   \n",
            "...        ...       ...       ...       ...  ...       ...       ...   \n",
            "6333  0.122404  0.061534  0.072745  0.487516  ... -0.600912 -0.396458   \n",
            "6334 -0.151443 -0.292548  0.728805  0.099745  ...  0.471309 -0.129264   \n",
            "6335  0.060867 -0.198952 -0.048505  0.399778  ... -0.388836 -0.281844   \n",
            "6336  0.107758 -0.028309 -0.078576  0.695667  ... -0.713587 -0.404793   \n",
            "6337  0.086278  0.060700 -0.196777  0.839079  ... -0.818626 -0.424666   \n",
            "\n",
            "           760       761       762       763       764       765       766  \\\n",
            "0     0.366749 -0.265988  0.431218 -0.324871 -0.247493 -0.118285 -0.087362   \n",
            "1     0.366749 -0.265988  0.431218 -0.324871 -0.247493 -0.118285 -0.087362   \n",
            "2     0.217846 -0.246668  0.486509 -0.605278 -0.285697 -0.020300  0.269508   \n",
            "3    -0.110847 -0.081150  0.296401 -0.576417 -0.218959 -0.117899  0.074203   \n",
            "4     0.477431 -0.415874  0.242342 -0.515072 -0.267169 -0.089304  0.021911   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "6333  0.002707 -0.284673  0.257750 -0.534936 -0.203614 -0.036683 -0.019442   \n",
            "6334  0.126192 -0.274693 -0.047577 -0.498724  0.329369  0.022788 -0.051143   \n",
            "6335 -0.055836 -0.424234  0.152672 -0.445652  0.111434 -0.005576 -0.034023   \n",
            "6336  0.199169 -0.219923  0.295736 -0.533563 -0.292966  0.029022  0.124669   \n",
            "6337 -0.258514 -0.371771  0.421988 -0.520781 -0.174146 -0.118261  0.117751   \n",
            "\n",
            "           767  \n",
            "0    -0.781328  \n",
            "1    -0.781328  \n",
            "2    -0.919939  \n",
            "3    -0.605774  \n",
            "4    -0.581207  \n",
            "...        ...  \n",
            "6333 -0.857985  \n",
            "6334 -0.196209  \n",
            "6335 -0.352328  \n",
            "6336 -0.625606  \n",
            "6337 -0.479659  \n",
            "\n",
            "[6338 rows x 770 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# BERT 모델과 토크나이저 불러오기\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 질문 설정하기\n",
        "question = \"성현이 뭐해?\"\n",
        "\n",
        "# 질문을 토큰 ID로 변환하기\n",
        "input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
        "\n",
        "# 모델을 사용하여 임베딩 생성하기\n",
        "question_embedding = model(input_ids).last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
        "\n",
        "# 모든 채팅 메시지와의 코사인 유사도 계산하기\n",
        "similarities = []\n",
        "for chat_embedding in chat_embeddings:\n",
        "    similarity = 1 - cosine(question_embedding, chat_embedding)\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# 가장 유사한 문장의 인덱스 찾기\n",
        "most_similar_index = similarities.index(max(similarities))\n",
        "\n",
        "# 가장 유사한 문장을 말한 사람 찾기\n",
        "most_similar_name = new_data['이름'][most_similar_index]\n",
        "\n",
        "# 가장 유사한 문장 출력하기\n",
        "most_similar_sentence = new_data['채팅'][most_similar_index]\n",
        "print(f\"가장 유사한 문장: {most_similar_sentence}\")\n",
        "print(f\"가장 유사한 문장을 말한 사람: {most_similar_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrw0fRXdmO8Y",
        "outputId": "3f299dce-9352-41e0-b0c0-382c95848ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가장 유사한 문장: 성현이 울산옴?\n",
            "가장 유사한 문장을 말한 사람: 3\n"
          ]
        }
      ]
    }
  ]
}